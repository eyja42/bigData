WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
2024-05-26 17:59:20,186 INFO client.RMProxy: Connecting to ResourceManager at master001/192.168.1.1:8032
2024-05-26 17:59:20,831 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-26 17:59:20,992 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/2024stu1_14/.staging/job_1678703754602_10835
2024-05-26 17:59:21,163 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 17:59:21,435 INFO input.FileInputFormat: Total input files to process : 40
2024-05-26 17:59:21,557 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 17:59:21,674 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 17:59:21,698 INFO mapreduce.JobSubmitter: number of splits:40
2024-05-26 17:59:21,899 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 17:59:21,979 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1678703754602_10835
2024-05-26 17:59:21,979 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-05-26 17:59:22,167 INFO conf.Configuration: found resource resource-types.xml at file:/home/workspace/hadoop-3.2.1/etc/hadoop/resource-types.xml
2024-05-26 17:59:22,181 INFO resource.ResourceUtils: Adding resource type - name = yarn.io/gpu, units = , type = COUNTABLE
2024-05-26 17:59:22,249 INFO impl.YarnClientImpl: Submitted application application_1678703754602_10835
2024-05-26 17:59:22,287 INFO mapreduce.Job: The url to track the job: http://114.212.190.95:8088/proxy/application_1678703754602_10835/
2024-05-26 17:59:22,288 INFO mapreduce.Job: Running job: job_1678703754602_10835
2024-05-26 17:59:28,398 INFO mapreduce.Job: Job job_1678703754602_10835 running in uber mode : false
2024-05-26 17:59:28,399 INFO mapreduce.Job:  map 0% reduce 0%
2024-05-26 17:59:34,467 INFO mapreduce.Job:  map 15% reduce 0%
2024-05-26 17:59:35,485 INFO mapreduce.Job:  map 38% reduce 0%
2024-05-26 17:59:36,494 INFO mapreduce.Job:  map 47% reduce 0%
2024-05-26 17:59:37,502 INFO mapreduce.Job:  map 73% reduce 0%
2024-05-26 17:59:38,507 INFO mapreduce.Job:  map 77% reduce 0%
2024-05-26 17:59:39,515 INFO mapreduce.Job:  map 98% reduce 0%
2024-05-26 17:59:40,520 INFO mapreduce.Job:  map 100% reduce 0%
2024-05-26 17:59:41,525 INFO mapreduce.Job:  map 100% reduce 100%
2024-05-26 18:00:00,627 INFO mapreduce.Job: Job job_1678703754602_10835 completed successfully
2024-05-26 18:00:00,749 INFO mapreduce.Job: Counters: 56
	File System Counters
		FILE: Number of bytes read=4921883
		FILE: Number of bytes written=19230761
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=5024834
		HDFS: Number of bytes written=4045908
		HDFS: Number of read operations=125
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Killed map tasks=1
		Launched map tasks=40
		Launched reduce tasks=1
		Data-local map tasks=34
		Rack-local map tasks=6
		Total time spent by all maps in occupied slots (ms)=237633
		Total time spent by all reduces in occupied slots (ms)=4630
		Total time spent by all map tasks (ms)=237633
		Total time spent by all reduce tasks (ms)=4630
		Total vcore-milliseconds taken by all map tasks=237633
		Total vcore-milliseconds taken by all reduce tasks=4630
		Total megabyte-milliseconds taken by all map tasks=243336192
		Total megabyte-milliseconds taken by all reduce tasks=4741120
	Map-Reduce Framework
		Map input records=158963
		Map output records=917614
		Map output bytes=33972161
		Map output materialized bytes=4922117
		Input split bytes=4507
		Combine input records=917614
		Combine output records=133143
		Reduce input groups=133143
		Reduce shuffle bytes=4922117
		Reduce input records=133143
		Reduce output records=24071
		Spilled Records=266286
		Shuffled Maps =40
		Failed Shuffles=0
		Merged Map outputs=40
		GC time elapsed (ms)=16871
		CPU time spent (ms)=157820
		Physical memory (bytes) snapshot=24506773504
		Virtual memory (bytes) snapshot=116572729344
		Total committed heap usage (bytes)=33595850752
		Peak Map Physical memory (bytes)=617857024
		Peak Map Virtual memory (bytes)=2851352576
		Peak Reduce Physical memory (bytes)=450318336
		Peak Reduce Virtual memory (bytes)=2861207552
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5020327
	File Output Format Counters 
		Bytes Written=4045908
2024-05-26 18:00:00,771 INFO client.RMProxy: Connecting to ResourceManager at master001/192.168.1.1:8032
2024-05-26 18:00:00,796 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-26 18:00:00,830 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/2024stu1_14/.staging/job_1678703754602_10836
2024-05-26 18:00:00,881 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:00,958 INFO input.FileInputFormat: Total input files to process : 1
2024-05-26 18:00:01,047 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:01,065 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1074126273_390924
java.io.IOException: Got error, status=ERROR, status message , ack with firstBadLink as 192.168.1.4:9866
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1778)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2024-05-26 18:00:01,067 WARN hdfs.DataStreamer: Abandoning BP-391144711-192.168.1.1-1668421113965:blk_1074126273_390924
2024-05-26 18:00:01,090 WARN hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[192.168.1.4:9866,DS-345392a4-0a3b-4b56-bf81-e496d7c2b10f,DISK]
2024-05-26 18:00:01,131 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:01,239 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1074126275_390926
java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:253)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1725)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2024-05-26 18:00:01,239 WARN hdfs.DataStreamer: Abandoning BP-391144711-192.168.1.1-1668421113965:blk_1074126275_390926
2024-05-26 18:00:01,255 WARN hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[192.168.1.4:9866,DS-345392a4-0a3b-4b56-bf81-e496d7c2b10f,DISK]
2024-05-26 18:00:01,272 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:01,297 INFO mapreduce.JobSubmitter: number of splits:1
2024-05-26 18:00:01,381 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:01,406 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1678703754602_10836
2024-05-26 18:00:01,406 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-05-26 18:00:01,432 INFO impl.YarnClientImpl: Submitted application application_1678703754602_10836
2024-05-26 18:00:01,436 INFO mapreduce.Job: The url to track the job: http://114.212.190.95:8088/proxy/application_1678703754602_10836/
2024-05-26 18:00:01,436 INFO mapreduce.Job: Running job: job_1678703754602_10836
2024-05-26 18:00:08,532 INFO mapreduce.Job: Job job_1678703754602_10836 running in uber mode : false
2024-05-26 18:00:08,533 INFO mapreduce.Job:  map 0% reduce 0%
2024-05-26 18:00:13,569 INFO mapreduce.Job:  map 100% reduce 0%
2024-05-26 18:00:19,602 INFO mapreduce.Job:  map 100% reduce 100%
2024-05-26 18:00:38,700 INFO mapreduce.Job: Job job_1678703754602_10836 completed successfully
2024-05-26 18:00:38,750 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=435470
		FILE: Number of bytes written=1328353
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4046023
		HDFS: Number of bytes written=646
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3491
		Total time spent by all reduces in occupied slots (ms)=3303
		Total time spent by all map tasks (ms)=3491
		Total time spent by all reduce tasks (ms)=3303
		Total vcore-milliseconds taken by all map tasks=3491
		Total vcore-milliseconds taken by all reduce tasks=3303
		Total megabyte-milliseconds taken by all map tasks=3574784
		Total megabyte-milliseconds taken by all reduce tasks=3382272
	Map-Reduce Framework
		Map input records=24071
		Map output records=24071
		Map output bytes=387322
		Map output materialized bytes=435470
		Input split bytes=115
		Combine input records=0
		Combine output records=0
		Reduce input groups=1074
		Reduce shuffle bytes=435470
		Reduce input records=24071
		Reduce output records=50
		Spilled Records=48142
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=198
		CPU time spent (ms)=4820
		Physical memory (bytes) snapshot=914395136
		Virtual memory (bytes) snapshot=5683118080
		Total committed heap usage (bytes)=1449132032
		Peak Map Physical memory (bytes)=592105472
		Peak Map Virtual memory (bytes)=2839973888
		Peak Reduce Physical memory (bytes)=322289664
		Peak Reduce Virtual memory (bytes)=2843144192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4045908
	File Output Format Counters 
		Bytes Written=646
2024-05-26 18:00:38,778 INFO client.RMProxy: Connecting to ResourceManager at master001/192.168.1.1:8032
2024-05-26 18:00:38,786 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2024-05-26 18:00:38,926 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/2024stu1_14/.staging/job_1678703754602_10837
2024-05-26 18:00:39,010 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:39,070 INFO input.FileInputFormat: Total input files to process : 1
2024-05-26 18:00:39,161 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:39,171 INFO hdfs.DataStreamer: Exception in createBlockOutputStream blk_1074126294_390945
java.io.IOException: Got error, status=ERROR, status message , ack with firstBadLink as 192.168.1.4:9866
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:134)
	at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:110)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1778)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1679)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:716)
2024-05-26 18:00:39,171 WARN hdfs.DataStreamer: Abandoning BP-391144711-192.168.1.1-1668421113965:blk_1074126294_390945
2024-05-26 18:00:39,190 WARN hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[192.168.1.4:9866,DS-345392a4-0a3b-4b56-bf81-e496d7c2b10f,DISK]
2024-05-26 18:00:39,210 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:39,310 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:39,335 INFO mapreduce.JobSubmitter: number of splits:1
2024-05-26 18:00:39,410 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2024-05-26 18:00:39,451 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1678703754602_10837
2024-05-26 18:00:39,452 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-05-26 18:00:39,471 INFO impl.YarnClientImpl: Submitted application application_1678703754602_10837
2024-05-26 18:00:39,474 INFO mapreduce.Job: The url to track the job: http://114.212.190.95:8088/proxy/application_1678703754602_10837/
2024-05-26 18:00:39,474 INFO mapreduce.Job: Running job: job_1678703754602_10837
2024-05-26 18:00:46,544 INFO mapreduce.Job: Job job_1678703754602_10837 running in uber mode : false
2024-05-26 18:00:46,545 INFO mapreduce.Job:  map 0% reduce 0%
2024-05-26 18:00:51,580 INFO mapreduce.Job:  map 100% reduce 0%
2024-05-26 18:00:55,603 INFO mapreduce.Job: Task Id : attempt_1678703754602_10837_r_000000_0, Status : FAILED
Error: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
	... 7 more
Caused by: java.lang.NullPointerException
	at com.hadoop.invertedindexer.InvertedIndexer$TFIDFReducer.<init>(InvertedIndexer.java:179)
	... 12 more

2024-05-26 18:01:00,650 INFO mapreduce.Job: Task Id : attempt_1678703754602_10837_r_000000_1, Status : FAILED
Error: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:135)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:614)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:174)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:168)
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:133)
	... 7 more
Caused by: java.lang.NullPointerException
	at com.hadoop.invertedindexer.InvertedIndexer$TFIDFReducer.<init>(InvertedIndexer.java:179)
	... 12 more

2024-05-26 18:04:03,295 INFO mapreduce.Job: Task Id : attempt_1678703754602_10837_r_000000_2, Status : FAILED
Container launch failed for container_1678703754602_10837_01_000005 : java.net.NoRouteToHostException: No Route to Host from  slave011/192.168.1.11 to slave004:33540 failed on socket timeout exception: java.net.NoRouteToHostException: No route to host; For more details see:  http://wiki.apache.org/hadoop/NoRouteToHost
	at sun.reflect.GeneratedConstructorAccessor45.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:833)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:784)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1549)
	at org.apache.hadoop.ipc.Client.call(Client.java:1491)
	at org.apache.hadoop.ipc.Client.call(Client.java:1388)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)
	at com.sun.proxy.$Proxy84.startContainers(Unknown Source)
	at org.apache.hadoop.yarn.api.impl.pb.client.ContainerManagementProtocolPBClientImpl.startContainers(ContainerManagementProtocolPBClientImpl.java:128)
	at sun.reflect.GeneratedMethodAccessor12.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy85.startContainers(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$Container.launch(ContainerLauncherImpl.java:160)
	at org.apache.hadoop.mapreduce.v2.app.launcher.ContainerLauncherImpl$EventProcessor.run(ContainerLauncherImpl.java:394)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.NoRouteToHostException: No route to host
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:533)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:700)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:804)
	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:421)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1606)
	at org.apache.hadoop.ipc.Client.call(Client.java:1435)
	... 19 more

2024-05-26 18:07:06,833 INFO mapreduce.Job:  map 100% reduce 100%
2024-05-26 18:07:25,891 INFO mapreduce.Job: Job job_1678703754602_10837 failed with state FAILED due to: Task failed task_1678703754602_10837_r_000000
Job failed as tasks failed. failedMaps:0 failedReduces:1 killedMaps:0 killedReduces: 0

2024-05-26 18:07:25,944 INFO mapreduce.Job: Counters: 40
	File System Counters
		FILE: Number of bytes read=0
		FILE: Number of bytes written=5150372
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4046023
		HDFS: Number of bytes written=0
		HDFS: Number of read operations=3
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=0
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Failed reduce tasks=4
		Launched map tasks=1
		Launched reduce tasks=4
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3359
		Total time spent by all reduces in occupied slots (ms)=5628
		Total time spent by all map tasks (ms)=3359
		Total time spent by all reduce tasks (ms)=5628
		Total vcore-milliseconds taken by all map tasks=3359
		Total vcore-milliseconds taken by all reduce tasks=5628
		Total megabyte-milliseconds taken by all map tasks=3439616
		Total megabyte-milliseconds taken by all reduce tasks=5763072
	Map-Reduce Framework
		Map input records=24071
		Map output records=133143
		Map output bytes=4655591
		Map output materialized bytes=4921883
		Input split bytes=115
		Combine input records=0
		Spilled Records=133143
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=143
		CPU time spent (ms)=3130
		Physical memory (bytes) snapshot=590180352
		Virtual memory (bytes) snapshot=2838392832
		Total committed heap usage (bytes)=824180736
		Peak Map Physical memory (bytes)=590180352
		Peak Map Virtual memory (bytes)=2838392832
	File Input Format Counters 
		Bytes Read=4045908
